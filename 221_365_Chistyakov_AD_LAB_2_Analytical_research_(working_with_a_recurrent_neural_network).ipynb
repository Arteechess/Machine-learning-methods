{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arteechess/Machine-learning-methods/blob/main/221_365_Chistyakov_AD_LAB_2_Analytical_research_(working_with_a_recurrent_neural_network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторная работа №2\n",
        "Аналитические исследования (работа с рекуррентной нейронной сетью)\n",
        "\n",
        "ФИО: Чистяков Артем Дмитриевич\n",
        "\n",
        "Группа: 221-365\n",
        "\n",
        "Номер 10 (2700 образцов)"
      ],
      "metadata": {
        "id": "cGqNhGwGuXu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np  # Добавлено: импорт библиотеки numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Загрузка данных\n",
        "try:\n",
        "    df = pd.read_excel(\"IMDB_dataset.xlsx\")\n",
        "    print(\"Файл Excel успешно загружен и прочитан.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Ошибка: Файл IMDB_dataset.xlsx не найден.\")\n",
        "    exit()  # Завершаем выполнение, если файл не найден\n",
        "\n",
        "# Вывод информации о данных\n",
        "print(\"Названия столбцов:\", df.columns.tolist())\n",
        "print(\"\\nПервые 5 строк датафрейма:\")\n",
        "print(df.head())\n",
        "\n",
        "# Предварительная обработка данных\n",
        "df.dropna(inplace=True)  # Удаление строк с пропущенными значениями\n",
        "df = df.drop_duplicates()  # Удаление дубликатов\n",
        "\n",
        "# Очистка текста\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)  # Удаление не-буквенных символов\n",
        "    text = text.lower()  # Приведение к нижнему регистру\n",
        "    return text\n",
        "\n",
        "df['review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# Лемматизация\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['review'] = df['review'].apply(lemmatize_text)\n",
        "\n",
        "# Выборка данных (без балансировки)\n",
        "df = df.sample(n=min(25000, len(df)), random_state=42)  # Сокращаем размер датасета, но не больше, чем есть\n",
        "\n",
        "print(\"Размер данных после предварительной обработки:\", len(df))\n",
        "\n",
        "reviews = df['review'].tolist()\n",
        "sentiments = df['sentiment'].tolist()\n",
        "\n",
        "#Размер выборки\n",
        "sample_size = 2700\n",
        "\n",
        "reviews = reviews[:sample_size]\n",
        "sentiments = sentiments[:sample_size]\n",
        "\n",
        "print(\"Размер выборки reviews:\", len(reviews))\n",
        "print(\"Размер выборки sentiments:\", len(sentiments))\n",
        "\n",
        "# Анализ данных\n",
        "positive_count = sentiments.count('positive')\n",
        "negative_count = sentiments.count('negative')\n",
        "ratio = positive_count / negative_count if negative_count > 0 else float('inf')\n",
        "\n",
        "print(\"\\nБазовая статистика:\")\n",
        "print(\"Количество отзывов в выборке:\", len(reviews))\n",
        "print(\"Количество положительных отзывов:\", positive_count)\n",
        "print(\"Количество отрицательных отзывов:\", negative_count)\n",
        "print(\"Соотношение положительных и отрицательных отзывов:\", round(ratio, 2))\n",
        "\n",
        "# Анализ длин отзывов\n",
        "print(\"\\nАнализ длин отзывов:\")\n",
        "review_lengths = [len(review) for review in reviews]\n",
        "avg_length = np.mean(review_lengths)\n",
        "max_length = np.max(review_lengths)\n",
        "min_length = np.min(review_lengths) # Исправлено: np.min вместо np.mean\n",
        "print(f\"Средняя длина отзыва: {avg_length}\")\n",
        "print(f\"Максимальная длина отзыва: {max_length}\")\n",
        "print(f\"Минимальная длина отзыва: {min_length}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTj7C_UAtQtO",
        "outputId": "4738831e-9e9c-4be7-ffa9-f54824621c7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл Excel успешно загружен и прочитан.\n",
            "Названия столбцов: ['review', 'sentiment']\n",
            "\n",
            "Первые 5 строк датафрейма:\n",
            "                                              review sentiment\n",
            "0  I thought this was a wonderful way to spend ti...  positive\n",
            "1  Probably my all-time favorite movie, a story o...  positive\n",
            "2  I sure would like to see a resurrection of a u...  positive\n",
            "3  This show was an amazing, fresh & innovative i...  negative\n",
            "4  Encouraged by the positive comments about this...  negative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер данных после предварительной обработки: 24898\n",
            "Размер выборки reviews: 2700\n",
            "Размер выборки sentiments: 2700\n",
            "\n",
            "Базовая статистика:\n",
            "Количество отзывов в выборке: 2700\n",
            "Количество положительных отзывов: 1337\n",
            "Количество отрицательных отзывов: 1363\n",
            "Соотношение положительных и отрицательных отзывов: 0.98\n",
            "\n",
            "Анализ длин отзывов:\n",
            "Средняя длина отзыва: 817.1029629629629\n",
            "Максимальная длина отзыва: 4185\n",
            "Минимальная длина отзыва: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исследована выборка из 2700 отзывов из IMDB Dataset.Соотношение классов:\n",
        "\n",
        "Распределение положительных и отрицательных отзывов в выборке примерно одинаковое (близко к 50/50). Это важно для обучения моделей, чтобы избежать смещения в сторону одного из классов.\n",
        "\n",
        "Длина отзывов варьируется от нескольких слов до нескольких сотен слов. Необходимо учитывать это при подготовке данных для обучения (например, использовать паддинг или обрезку).\n",
        "\n",
        "Анализ частоты слов может быть полезен для определения наиболее важных слов, которые характеризуют положительные и отрицательные отзывы. На этом этапе выводится только топ индексов слов, потому что для получения слов нужно сделать еще 1 запрос: imdb.get_word_index()\n"
      ],
      "metadata": {
        "id": "fnNXv3S1nsDj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-qcr8g6WAbULrsXGaQgDAt4pWKNslpM0",
      "authorship_tag": "ABX9TyO6Mj16qk4KpfKGRqM/qz6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}